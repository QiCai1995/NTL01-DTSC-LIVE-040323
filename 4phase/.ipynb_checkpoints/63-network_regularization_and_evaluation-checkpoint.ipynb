{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Regularization and Evaluation of Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/flatiron-school/NTL01-DTSC-LIVE-040323/blob/main/4phase/63-network_regularization_and_evaluation.ipynb\" \n",
    "target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (23.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (2.3.1)\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.12.0-cp38-cp38-macosx_10_15_x86_64.whl (230.1 MB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Collecting flatbuffers>=2.0 (from tensorflow)\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow) (2.10.0)\n",
      "Collecting jax>=0.3.15 (from tensorflow)\n",
      "  Using cached jax-0.4.12-py3-none-any.whl\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-16.0.0-py2.py3-none-macosx_10_9_x86_64.whl (26.7 MB)\n",
      "Collecting numpy<1.24,>=1.22 (from tensorflow)\n",
      "  Using cached numpy-1.23.5-cp38-cp38-macosx_10_9_x86_64.whl (18.1 MB)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow) (20.4)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-4.23.2-cp37-abi3-macosx_10_9_universal2.whl (400 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.3/400.3 kB\u001b[0m \u001b[31m665.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow) (50.3.0.post20201103)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow)\n",
      "  Using cached typing_extensions-4.6.3-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow) (1.31.0)\n",
      "Collecting tensorboard<2.13,>=2.12 (from tensorflow)\n",
      "  Using cached tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
      "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow)\n",
      "  Using cached tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
      "Collecting keras<2.13,>=2.12.0 (from tensorflow)\n",
      "  Using cached keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.32.0-cp38-cp38-macosx_10_14_x86_64.whl (1.7 MB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.35.1)\n",
      "Collecting ml-dtypes>=0.1.0 (from jax>=0.3.15->tensorflow)\n",
      "  Downloading ml_dtypes-0.2.0-cp38-cp38-macosx_10_9_universal2.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m900.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy>=1.7 (from jax>=0.3.15->tensorflow)\n",
      "  Using cached scipy-1.10.1-cp38-cp38-macosx_10_9_x86_64.whl (35.0 MB)\n",
      "Collecting importlib-metadata>=4.6 (from jax>=0.3.15->tensorflow)\n",
      "  Using cached importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.54.2-cp38-cp38-macosx_10_10_universal2.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.22.0)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.3.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.24.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.0-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from packaging->tensorflow) (2.4.7)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.6)\n",
      "Requirement already satisfied: aiohttp<4.0.0dev,>=3.6.2 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (3.6.2)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.13,>=2.12->tensorflow)\n",
      "  Downloading google_auth-2.19.1-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.25.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2020.6.20)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: attrs>=17.3.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (20.2.0)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.7.5)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from aiohttp<4.0.0dev,>=3.6.2->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (1.6.2)\n",
      "Installing collected packages: libclang, flatbuffers, typing-extensions, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, protobuf, numpy, keras, importlib-metadata, grpcio, absl-py, scipy, ml-dtypes, google-auth, jax, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.3.0\n",
      "    Uninstalling tensorflow-estimator-2.3.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.13.0\n",
      "    Uninstalling protobuf-3.13.0:\n",
      "      Successfully uninstalled protobuf-3.13.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.18.5\n",
      "    Uninstalling numpy-1.18.5:\n",
      "      Successfully uninstalled numpy-1.18.5\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.4.3\n",
      "    Uninstalling Keras-2.4.3:\n",
      "      Successfully uninstalled Keras-2.4.3\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 2.0.0\n",
      "    Uninstalling importlib-metadata-2.0.0:\n",
      "      Successfully uninstalled importlib-metadata-2.0.0\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.31.0\n",
      "    Uninstalling grpcio-1.31.0:\n",
      "      Successfully uninstalled grpcio-1.31.0\n",
      "  Attempting uninstall: absl-py\n",
      "    Found existing installation: absl-py 0.10.0\n",
      "    Uninstalling absl-py-0.10.0:\n",
      "      Successfully uninstalled absl-py-0.10.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.5.2\n",
      "    Uninstalling scipy-1.5.2:\n",
      "      Successfully uninstalled scipy-1.5.2\n",
      "  Attempting uninstall: google-auth\n",
      "    Found existing installation: google-auth 1.22.0\n",
      "    Uninstalling google-auth-1.22.0:\n",
      "      Successfully uninstalled google-auth-1.22.0\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 0.4.1\n",
      "    Uninstalling google-auth-oauthlib-0.4.1:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.1\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.3.0\n",
      "    Uninstalling tensorboard-2.3.0:\n",
      "      Successfully uninstalled tensorboard-2.3.0\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.3.1\n",
      "    Uninstalling tensorflow-2.3.1:\n",
      "      Successfully uninstalled tensorflow-2.3.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-core 1.22.4 requires google-auth<2.0dev,>=1.21.1, but you have google-auth 2.19.1 which is incompatible.\n",
      "google-cloud-storage 1.31.2 requires google-auth<2.0dev,>=1.11.0, but you have google-auth 2.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed absl-py-1.4.0 flatbuffers-23.5.26 google-auth-2.19.1 google-auth-oauthlib-1.0.0 grpcio-1.54.2 importlib-metadata-6.6.0 jax-0.4.12 keras-2.12.0 libclang-16.0.0 ml-dtypes-0.2.0 numpy-1.23.5 protobuf-4.23.2 scipy-1.10.1 tensorboard-2.12.3 tensorboard-data-server-0.7.0 tensorflow-2.12.0 tensorflow-estimator-2.12.0 tensorflow-io-gcs-filesystem-0.32.0 typing-extensions-4.6.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (2.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install --no-deps tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:31:45.552744Z",
     "start_time": "2023-06-12T19:31:45.416712Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "SciKeras requires TensorFlow >= 2.7.0.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-77438beb2201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mscikeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/scikeras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf_version\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMIN_TF_VERSION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pragma: no cover\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTF_VERSION_ERR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: SciKeras requires TensorFlow >= 2.7.0."
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_sample_images\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.wrappers import scikit_learn\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir, os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras==2.9.0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: keras\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: Keras 2.3.1\n",
      "    Uninstalling Keras-2.3.1:\n",
      "      Successfully uninstalled Keras-2.3.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.12.0 requires keras<2.13,>=2.12.0, but you have keras 2.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed keras-2.9.0\n",
      "Collecting tensorflow==2.9.0\n",
      "  Downloading tensorflow-2.9.0-cp38-cp38-macosx_10_14_x86_64.whl (228.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.5/228.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (1.6.3)\n",
      "Collecting flatbuffers<2,>=1.12 (from tensorflow==2.9.0)\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (0.3.3)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (2.10.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (1.1.2)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (16.0.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (3.3.0)\n",
      "Requirement already satisfied: packaging in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (20.4)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (4.23.2)\n",
      "Requirement already satisfied: setuptools in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (50.3.0.post20201103)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (4.6.3)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (1.12.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (0.32.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (1.54.2)\n",
      "Collecting tensorboard<2.10,>=2.9 (from tensorflow==2.9.0)\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.0)\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorflow==2.9.0) (2.9.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow==2.9.0) (0.35.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.19.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.0)\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.3.1)\n",
      "Collecting protobuf>=3.9.2 (from tensorflow==2.9.0)\n",
      "  Downloading protobuf-3.19.6-cp38-cp38-macosx_10_9_x86_64.whl (980 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m980.4/980.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.24.0)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.0)\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-macosx_10_9_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from packaging->tensorflow==2.9.0) (2.4.7)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (4.1.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.2.7)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (4.6)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.25.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (1.3.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (2020.6.20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.0) (3.1.0)\n",
      "Installing collected packages: flatbuffers, tensorflow-estimator, tensorboard-data-server, protobuf, google-auth-oauthlib, tensorboard, tensorflow\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 23.5.26\n",
      "    Uninstalling flatbuffers-23.5.26:\n",
      "      Successfully uninstalled flatbuffers-23.5.26\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.12.0\n",
      "    Uninstalling tensorflow-estimator-2.12.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
      "  Attempting uninstall: tensorboard-data-server\n",
      "    Found existing installation: tensorboard-data-server 0.7.0\n",
      "    Uninstalling tensorboard-data-server-0.7.0:\n",
      "      Successfully uninstalled tensorboard-data-server-0.7.0\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 4.23.2\n",
      "    Uninstalling protobuf-4.23.2:\n",
      "      Successfully uninstalled protobuf-4.23.2\n",
      "  Attempting uninstall: google-auth-oauthlib\n",
      "    Found existing installation: google-auth-oauthlib 1.0.0\n",
      "    Uninstalling google-auth-oauthlib-1.0.0:\n",
      "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.12.3\n",
      "    Uninstalling tensorboard-2.12.3:\n",
      "      Successfully uninstalled tensorboard-2.12.3\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.12.0\n",
      "    Uninstalling tensorflow-2.12.0:\n",
      "      Successfully uninstalled tensorflow-2.12.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-api-core 1.22.4 requires google-auth<2.0dev,>=1.21.1, but you have google-auth 2.19.1 which is incompatible.\n",
      "google-cloud-storage 1.31.2 requires google-auth<2.0dev,>=1.11.0, but you have google-auth 2.19.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed flatbuffers-1.12 google-auth-oauthlib-0.4.6 protobuf-3.19.6 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorflow-2.9.0 tensorflow-estimator-2.9.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install keras==2.9.0\n",
    "#!pip install tensorflow==2.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (0.10.0)\n",
      "Requirement already satisfied: packaging>=0.21 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikeras) (20.4)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikeras) (1.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from packaging>=0.21->scikeras) (2.4.7)\n",
      "Requirement already satisfied: six in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from packaging>=0.21->scikeras) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/echocai/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages (from scikit-learn>=1.0.0->scikeras) (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "# !pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:31:45.710738Z",
     "start_time": "2023-06-12T19:31:45.553743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Objectives\n",
    "\n",
    "- use `keras` to code up a neural network model;\n",
    "- explain dropout and early stopping as distinctive forms of regularization in neural networks;\n",
    "- use wrappers inside `keras` to make models that can jibe with `sklearn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:31:45.868712Z",
     "start_time": "2023-06-12T19:31:45.711742Z"
    }
   },
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data.astype('float32')\n",
    "y = digits.target.astype('float32')\n",
    "\n",
    "y_binary = y % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:16.196771Z",
     "start_time": "2023-06-12T19:31:45.869712Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y_binary, epochs=50, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to know:\n",
    "\n",
    "- The data and labels in `fit()` need to be numpy arrays, not `pandas` dfs.\n",
    "- Scaling your data will have a large impact on your model.\n",
    "   > For our traditional input features, we would use a scaler object. For images, as long as the minimum value is 0, we can simply divide through by the maximum pixel intensity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting data ready for modeling\n",
    "**Preprocessing**:\n",
    "\n",
    "- use train_test_split to create X_train, y_train, X_test, and y_test\n",
    "- Split training data into pure_train and validation sets.\n",
    "- Scale the pixel intensity to a value between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling our input variables will help speed up our neural network.\n",
    "\n",
    "Since our minimum intensity is 0, we can normalize the inputs by dividing each value by the max value (16)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:16.306834Z",
     "start_time": "2023-06-12T19:32:16.197713Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test =\\\n",
    "    train_test_split(X, y_binary, random_state=42, test_size=0.2)\n",
    "\n",
    "X_pure_train, X_val, y_pure_train, y_val =\\\n",
    "    train_test_split(X_train, y_train, random_state=42, test_size=0.2)\n",
    "\n",
    "X_pure_train, X_val, X_test = X_pure_train/16, X_val/16, X_test/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For activation, let's start with the familiar sigmoid function, and see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:16.998889Z",
     "start_time": "2023-06-12T19:32:16.307711Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# We will start with our trusty sigmoid function.\n",
    "# What does input dimension correspond to?\n",
    "model.add(Dense(12, activation='sigmoid', input_dim=64))\n",
    "model.add(Dense(8, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='SGD' ,\n",
    "              # We use binary_crossentropy for a binary loss function\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Assign the variable history to store the results,\n",
    "# and set verbose=1 so we can see the output. To see\n",
    "# only the metrics at the end of each epoch, set verbose=2.\n",
    "results = model.fit(X_pure_train, y_pure_train, epochs=10, batch_size=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access the history of our model via `results.history`.\n",
    "Use __dict__ to take a tour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:17.106887Z",
     "start_time": "2023-06-12T19:32:16.999887Z"
    }
   },
   "outputs": [],
   "source": [
    "results.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:17.404340Z",
     "start_time": "2023-06-12T19:32:17.107887Z"
    }
   },
   "outputs": [],
   "source": [
    "sigmoid_loss = results.history['loss']\n",
    "sigmoid_accuracy = results.history['accuracy']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=sigmoid_loss, ax=ax1, label='loss')\n",
    "sns.lineplot(x=results.epoch, y=sigmoid_accuracy, ax=ax2, label='accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have two plots above both relating to the quality of our model.  The left-hand plot is our loss. It uses the probabilities associated with our predictions to judge how well our prediction fits reality. We want it to decrease as far as possible.\n",
    "\n",
    "The accuracy judges how well the predictions are after applying the threshold at the output layer.  We want accuracy to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at our loss, it is still decreasing. That is a signal that our model is **still learning**. If our model is still learning, we can allow it to get better by turning a few dials.\n",
    "\n",
    "Let's:\n",
    "- increase the number of epochs;\n",
    "- change sigmoid activation in the hidden layers to ReLU; and\n",
    "- decrease the batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:17.514247Z",
     "start_time": "2023-06-12T19:32:17.405220Z"
    }
   },
   "outputs": [],
   "source": [
    "X_pure_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:26.686278Z",
     "start_time": "2023-06-12T19:32:17.516219Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Assign the variable history to store the results,\n",
    "# and set verbose=1 so we can see the output.\n",
    "results = model.fit(X_pure_train, y_pure_train, epochs=100, batch_size=None, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:26.968219Z",
     "start_time": "2023-06-12T19:32:26.687221Z"
    }
   },
   "outputs": [],
   "source": [
    "sigmoid_loss = results.history['loss']\n",
    "sigmoid_accuracy = results.history['accuracy']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=sigmoid_loss, ax=ax1, label='loss')\n",
    "sns.lineplot(x=results.epoch, y=sigmoid_accuracy, ax=ax2, label='accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we increase the learning rate to a very high number, we see that our model overshoots the minimum, and starts bouncing all around."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:36.163251Z",
     "start_time": "2023-06-12T19:32:26.969220Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "sgd = SGD(learning_rate=9)\n",
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=sgd,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                    epochs=30, batch_size=10, verbose=1)\n",
    "\n",
    "relu_loss = results.history['loss']\n",
    "relu_accuracy = results.history['accuracy']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=relu_loss, ax=ax1, label='loss')\n",
    "sns.lineplot(x=results.epoch, y=relu_accuracy, ax=ax2, label='accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "We have been looking only at our training set. Let's add in our validation set to the picture. Check the docstring for the `.fit()` method and add in our validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:36.302218Z",
     "start_time": "2023-06-12T19:32:36.164219Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:48.526081Z",
     "start_time": "2023-06-12T19:32:36.303219Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                   validation_data=(X_val, y_val),\n",
    "                   epochs=30, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:48.854053Z",
     "start_time": "2023-06-12T19:32:48.527052Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>One answer here</summary>\n",
    "<code>model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                   validation_data=(X_val, y_val),\n",
    "                   epochs=30, batch_size=10)\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:48.964054Z",
     "start_time": "2023-06-12T19:32:48.855086Z"
    }
   },
   "outputs": [],
   "source": [
    "results.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connecting with `sklearn`\n",
    "\n",
    "The `keras.wrappers` submodule means that we can turn `keras` models into estimators that `sklearn` tools will recognize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:49.655082Z",
     "start_time": "2023-06-12T19:32:48.965053Z"
    }
   },
   "outputs": [],
   "source": [
    "# This will throw an error.\n",
    "\n",
    "cross_val_score(model, X_pure_train, y_pure_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:58.834328Z",
     "start_time": "2023-06-12T19:32:58.730299Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, activation='relu', input_dim=64))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:32:59.976430Z",
     "start_time": "2023-06-12T19:32:59.865408Z"
    }
   },
   "outputs": [],
   "source": [
    "keras_model = KerasClassifier(build_model,\n",
    "                                          epochs=50,\n",
    "                                          batch_size=32,\n",
    "                                          verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:33:02.033186Z",
     "start_time": "2023-06-12T19:33:01.922187Z"
    }
   },
   "outputs": [],
   "source": [
    "type(keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:33:26.192775Z",
     "start_time": "2023-06-12T19:33:03.647753Z"
    }
   },
   "outputs": [],
   "source": [
    "cross_val_score(keras_model, X_pure_train, y_pure_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does regularization make sense in the context of neural networks? <br/>\n",
    "\n",
    "Yes! We still have all of the salient ingredients: a loss function, overfitting vs. underfitting, and coefficients (weights) that could get too large.\n",
    "\n",
    "But there are now a few different flavors besides L1 and L2 regularization. (Note that L1 regularization is not common in the context of  neural networks.)\n",
    "\n",
    "We'll add a few more layers to give regularization a better chance of making a difference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:33:33.872825Z",
     "start_time": "2023-06-12T19:33:30.131824Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=64))\n",
    "\n",
    "# We can add L2 (or L1) regularization right into\n",
    "# the layer with the kernel_regularizer parameter.\n",
    "\n",
    "model.add(Dense(20, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.05)))\n",
    "\n",
    "# Note that there is also a bias_regularizer,\n",
    "# but this tends to have less effect.\n",
    "\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_pure_train, y_pure_train, epochs=20, batch_size=32,\n",
    "                    verbose=0, validation_data=(X_val, y_val))\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding L2 to multiple layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:33:39.018732Z",
     "start_time": "2023-06-12T19:33:34.868769Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu',\n",
    "                input_dim=64))\n",
    "model.add(Dense(20, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.01)))\n",
    "\n",
    "model.add(Dense(12, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.01)))\n",
    "model.add(Dense(12, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.01)))\n",
    "model.add(Dense(12, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.01)))\n",
    "model.add(Dense(8, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.01)))\n",
    "model.add(Dense(4, activation='relu',\n",
    "                kernel_regularizer=l2(l2=0.01)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_pure_train, y_pure_train, epochs=20, batch_size=32,\n",
    "                    verbose=0, validation_data=(X_val, y_val))\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "We can also specify a dropout layer in keras, which randomly shuts off different nodes during training. This can help to prevent overfitting.\n",
    "\n",
    "![drop_out](images/drop_out.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "To add dropout to a `keras` network, simply add it as though it were a layer. It will apply to the immediately preceding layer.\n",
    "\n",
    "Add Dropout to one or more layers below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:33:47.957908Z",
     "start_time": "2023-06-12T19:33:40.019305Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=64))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_pure_train, y_pure_train, epochs=50,\n",
    "                    batch_size= 32, verbose=0,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>One answer here</summary>\n",
    "<code>model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=64))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_pure_train, y_pure_train, epochs=50,\n",
    "                    batch_size= 32, verbose=0,\n",
    "                    validation_data=(X_val, y_val))\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:33:49.228412Z",
     "start_time": "2023-06-12T19:33:49.133435Z"
    }
   },
   "outputs": [],
   "source": [
    "results.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also tell our neural network to stop once it stops realizing any gain.\n",
    "\n",
    "Here we tell it to stop once the a very small positive change in the validation loss occurs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:33:51.476305Z",
     "start_time": "2023-06-12T19:33:50.273576Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=64))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define the EarlyStopping object\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=1e-4,\n",
    "                           verbose=1,\n",
    "                           mode='min')\n",
    "\n",
    "# Place this in a list as the value of the `callbacks` parameter\n",
    "# in the `.fit()` method.\n",
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                    epochs=20, batch_size=32,\n",
    "                    verbose=0, validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "That probably stopped too early. We can specify the number of epochs in which it doesn't see decrease in the loss with the `patience` parameter. Modify the code below to include an Early Stop with a patience of 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:33:59.223710Z",
     "start_time": "2023-06-12T19:33:52.522113Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=64))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define the EarlyStopping object\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=1e-8,\n",
    "                           verbose=1, patience=5,\n",
    "                           mode='min')\n",
    "\n",
    "# Place this in a list as the value of the `callbacks` parameter\n",
    "# in the `.fit()` method.\n",
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                    epochs=50, batch_size= 32,\n",
    "                    verbose=0, validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>One answer here</summary>\n",
    "<code>model = Sequential()\n",
    "model.add(Dense(30, activation='relu', input_dim=64))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation ='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Define the EarlyStopping object\n",
    "\n",
    "\n",
    "\n",
    "# Place this in a list as the value of the `callbacks` parameter\n",
    "# in the `.fit()` method.\n",
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                    epochs=50, batch_size= 32,\n",
    "                    verbose=0, validation_data=(X_val, y_val),\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "train_loss = results.history['loss']\n",
    "train_acc = results.history['accuracy']\n",
    "val_loss = results.history['val_loss']\n",
    "val_acc = results.history['val_accuracy']\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "sns.lineplot(x=results.epoch, y=train_loss, ax=ax1, label='train_loss')\n",
    "sns.lineplot(x=results.epoch, y=train_acc, ax=ax2, label='train_accuracy')\n",
    "\n",
    "sns.lineplot(x=results.epoch, y=val_loss, ax=ax1, label='val_loss')\n",
    "sns.lineplot(x=results.epoch, y=val_acc, ax=ax2, label='val_accuracy');</code>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:34:00.350679Z",
     "start_time": "2023-06-12T19:34:00.242679Z"
    }
   },
   "outputs": [],
   "source": [
    "results.history['val_accuracy'][-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification and Softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's return to the problem of predicting digits 0 through 9."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:34:01.480390Z",
     "start_time": "2023-06-12T19:34:01.340391Z"
    }
   },
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:34:02.617437Z",
     "start_time": "2023-06-12T19:34:02.506438Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=42,\n",
    "                                                    test_size=0.2)\n",
    "X_pure_train, X_val, y_pure_train, y_val =\\\n",
    "    train_test_split(X_train, y_train,\n",
    "                     random_state=42, test_size=0.2)\n",
    "X_pure_train, X_val, X_test = X_pure_train/16, X_val/16, X_test/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a multiclass output, our neural net expects our target to be in a certain form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:34:03.708089Z",
     "start_time": "2023-06-12T19:34:03.601210Z"
    }
   },
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse=False)\n",
    "y_pure_train = ohe.fit_transform(y_pure_train.reshape(-1,1))\n",
    "y_val = ohe.transform(y_val.reshape(-1,1))\n",
    "y_test = ohe.transform(y_test.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:34:04.815190Z",
     "start_time": "2023-06-12T19:34:04.709090Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:34:23.577089Z",
     "start_time": "2023-06-12T19:34:05.787089Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model from above, but now with ten output neurons:\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(12, activation='relu', input_dim=64))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(X_pure_train, y_pure_train,\n",
    "                   epochs=50, batch_size=10,\n",
    "                   validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Softmax}(x_{i}) = \\frac{\\exp(x_i)}{\\sum_j \\exp(x_j)}$$\n",
    "\n",
    "The sofmax function outputs a number between 0 and 1 for each of our classes.  All of the probabilities of the classes sum up to 1.\n",
    "\n",
    "The number of nodes in our output layer equals the number of categories in our dataset.\n",
    "\n",
    "We also need a new loss function: **categorical crossentropy**, which calculates a separate loss for each label and then sums the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:34:24.738119Z",
     "start_time": "2023-06-12T19:34:24.630115Z"
    }
   },
   "outputs": [],
   "source": [
    "history = results.history\n",
    "training_loss = history['loss']\n",
    "val_loss = history['val_loss']\n",
    "training_accuracy = history['accuracy']\n",
    "val_accuracy = history['val_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:34:26.215090Z",
     "start_time": "2023-06-12T19:34:25.828091Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, (ax1,ax2) = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "\n",
    "sns.lineplot(x=list(range(len(training_loss))),\n",
    "             y=training_loss, color='r', label='training', ax=ax1)\n",
    "sns.lineplot(x=list(range(len(val_loss))),\n",
    "             y=val_loss, color='b', label='validation', ax=ax1)\n",
    "sns.lineplot(x=list(range(len(training_loss))),\n",
    "             y=training_accuracy, color='r', label='training',ax=ax2)\n",
    "sns.lineplot(x=list(range(len(val_loss))),\n",
    "             y=val_accuracy, color='b', label='validation',ax=ax2)\n",
    "ax1.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:34:27.432123Z",
     "start_time": "2023-06-12T19:34:27.261089Z"
    }
   },
   "outputs": [],
   "source": [
    "y_hat_test = np.argmax(model.predict(X_test), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-12T19:34:28.527564Z",
     "start_time": "2023-06-12T19:34:28.434593Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_restore = ohe.inverse_transform(y_test)\n",
    "confusion_matrix(y_test_restore, y_hat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow, look at that performance!  \n",
    "\n",
    "That is great, but remember, we were dealing with simple black and white images.  With color, our basic neural net will have less success.\n",
    "\n",
    "We will explore more advanced tools in the coming days.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "intro-to-keras.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
